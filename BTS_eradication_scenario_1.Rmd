---
title: "BTS Eradication Scenario 1"
author: "Kelly Mistry"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reshape2)
library(ggplot2)
library(dplyr)
library(here)
library(tictoc)
library(fdrtool)
library(jagsUI)
library(scales)
library(vctrs)

source(here("Scripts/00_user_inputs.R"))
source(here("Scripts/01_model_functions.R"))
source(here("Scripts/02_results_functions.R"))
```

## Target area for eradication

-   Close population (by necessity, since the model requires that currently)
-   approximately 50 ha, in a rectangular shape; 220 m wide X 2260 m long
    -   220 m is the length of the transects used in the 5 ha CP area, which many experiments used and so calculating costs should be fairly easy
    -   50 ha is approximately the smallest area that ADS is used for (because of cost)
-   113 transects, with 20 m between transects, with traps spaced every 20 m on the transect
    -   Based on design for HMU experiment, although they also had bait tubes interspersed evenly between traps, so it was trap - 10 m - tube - 10 m - trap, etc

#### Eradication scenario alternatives & choices

-   Alternative 1: use all methods, in as intense a combination as possible in order to maximize impact over a set amount of time, then take stock of progress
-   Alternative 2: use ADS and visual survey until predicted size distribution reaches more than 90% small snakes, at which point switch to visual only for the amount of time it would take those snakes to grow big enough to be susceptible to mice baits again, and take stock to see where the population is at

#### Alternative 1

-   6 consequtive weeks of trapping per transect, with 28-29 neighboring transects being trapped per quarter
    -   Also based on HMU experimental design
    -   28 transects in the first 3 quarters (24.8% of the area), and 29 in the last quarter (25.7%)
    -   Trap in weeks 3 - 9
-   ADS needs to occur outside of trapping & visual survey weeks - it can occur in the 11th, 12th or 1st weeks of the quarter
    -   Target area coverage for ADS can vary, from 0 - 100% for alternative management choices in this scenario
    -   Target ADS bait density = 120 cartridges/ha/day, using an automatic release system that drops 1 cartridge/9 m. The flight path will be 9 m apart, in a back and forth pattern to provide full coverage of an area.
        -   Based on Goetz et al. 2021, which used the maximum rate of release allowed by the EPA. They didn't cite why they chose 9 m apart for the flight path, but it seems likely that is based on past research (i.e. the automatic release system drops 1 cartridge per 9 m, presumably based on past research about attractiveness/effectiveness of the bait) - it would be good to check though, to see if I can get a better reference for this choice.
-   Visual survey on 2nd and 10th weeks of quarter (before and after trapping), on the same transects being trapped in that quarter
    -   Visual surveys could also occur during the trapping weeks, that could be an alternatives choice (probably based on cost)
    -   1 team can cover \~4 transects per night (based on Nafus et al. 2021), so to cover 28 transects in 1 week, these are some combinations:
        -   1 team can cover all transects once in a week
        -   More teams could cover the area more than once, but that would require different numbers of people per night, so for now I'll just stick with 1 team

```{r alternative_1_set_up}

# Number of teams for visual survey
teams <- 1

# Adjusting effort hours per method if necessary (there are defaults)
effort_erad_methods <- list()
effort_erad_methods$ADS <- 4
effort_erad_methods$visual <- 4*2*teams
effort_erad_methods$trap <- 12 # assumes that the trap is only working at night - check to see what the convention is for BTS
effort_erad_methods$bait_tube <- 12 # Same as trap

# Parameters that may be changed or subject to sensitivity analysis or to simulate over
# Set study/eradication area size, which dictates both K and the initial population
area_size <- 50 # increase to 50 for real runs, this is just to get everything working quicker

# Set carrying capacity for this population:
K <- 119*area_size

## For initial population, based on previous runs to find roughly eqiulibrium N and size distribution:
N <- 100*area_size
size_dist <- c(0.6, 0.1, 0.1, 0.2)


# Growth probability (p_g)
g_density_prob <- 0.75 

# Number of quarters to generate - 1 year
erad_quarter_time_step <- 4
day_time_step <- 91

# Quarters where eradication methods are used, and which days in that quarter:
erad_quarters <- list()
erad_quarters$ADS <- c(2, 3)
erad_quarters$visual <- c(1:4)
erad_quarters$trap <- c(1:4)
erad_quarters$bait_tube <- c(1:4)
erad_days <- list()
erad_days$ADS <- c(7*1, 7*11, 7*12)
erad_days$visual <- seq(7*2, (7*11 - 1), 2)
erad_days$trap <- seq(7*3, (7*10 - 1), 2)
erad_days$bait_tube <- seq(7*11, 7*12, 3)

# Coverage for each method (totally arbitrary, adjust later)
erad_coverage <- list()
erad_coverage$ADS <- 1
erad_coverage$visual <- 4/113
erad_coverage$trap <- 28/113
erad_coverage$bait_tube <- 28/113
# Overlap of ADS over transects
ADS_overlap_on_transect <- 1 # i.e. total area coverage, by at least one method 

# Running model 
erad_quarter_results <- quarter_operations(initial_N = N, 
                                           initial_size_dist = size_dist, 
                                           p_g = g_density_prob,
                                           lambda = lambda,
                                           total_quarters = erad_quarter_time_step,
                                           total_days = day_time_step,
                                           erad = "on",
                                           erad_method = erad_methods)

# Plotting the total population in each quarter
erad_plot_1 <- ggplot(erad_quarter_results$all_quarters, 
                      aes(x = Quarter, fill = size_category)) +
  geom_bar() +
  geom_hline(yintercept = K) +
  theme_bw() +
  scale_x_continuous(breaks = unique(erad_quarter_results$all_quarters$Quarter), labels = unique(erad_quarter_results$all_quarters$Quarter))

```

To incorporate uncertainty into these results, initial N values will come from 25 draws (increase the number later) from a normal distribution, currently with mean of 100 and SD of 10. I'll then take all of these results, and put them through the estimation model...I guess? What do I want to know about these results first though. Maybe the mean of impact, and some measurement of variance, from the eradication regime? In terms of total N, as well as N for each size class.

```{r alternative_1_variants}

# Incorporating uncertainty about the starting population by simulating a range of values - 50 iterations for presentation results
N_list <- round(rnorm(50, 100, 10))*area_size

# Number of variants for looping
num_variants <- length(N_list)

# List of quarter results
erad_results_list <- list()

for(variant in 1:num_variants) {
  # Running model 
  erad_results_list[[variant]] <- quarter_operations(initial_N = N_list[variant], 
                                           initial_size_dist = size_dist, 
                                           p_g = g_density_prob,
                                           lambda = lambda,
                                           total_quarters = erad_quarter_time_step,
                                           total_days = day_time_step,
                                           erad = "on",
                                           erad_method = erad_methods)
  print(paste0("iteration ", variant, " is complete"))
}

# Save outputs 
saveRDS(erad_results_list, file = here("Results", "scenario_1", "IBM_outputs_alt_1_50.RDS"))


erad_plot_data <- list()
for(variant in 1:num_variants) {
  erad_plot_data[[variant]] <- list()
  results <- erad_results_list[[variant]]$all_quarters
  for(quarter in 1:erad_quarter_time_step) {
    erad_plot_data[[variant]][[quarter]] <- as.data.frame(matrix(NA, nrow = 4, ncol = 2))
    colnames(erad_plot_data[[variant]][[quarter]]) <- c("size_category", "N")
    for(size in 1:length(size_class_names)) {
      erad_plot_data[[variant]][[quarter]][size, 1] <- size_class_names[size]
      erad_plot_data[[variant]][[quarter]][size, 2] <- nrow(results[results$Quarter == (quarter+1) & results$size_category == size_class_names[size],])
    }
  }
  names(erad_plot_data[[variant]]) <- paste0("Quarter_", c(1:4))
}
names(erad_plot_data) <- paste0("variant_", c(1:num_variants))  

erad_plot_data_melted <- melt(erad_plot_data, id.vars = colnames(erad_plot_data[[1]][[1]]))
colnames(erad_plot_data_melted)[c(3:4)] <- c("Quarter", "variant")
erad_plot_data_melted$size_category <- factor(erad_plot_data_melted$size_category, levels = size_class_names)
erad_plot_data_melted$variant <- factor(erad_plot_data_melted$variant, levels = paste0("variant_", c(1:num_variants)))

variants_plot <- ggplot(erad_plot_data_melted, aes(x = Quarter, y = N, color = variant)) +
  geom_path(aes(group = variant), show.legend = FALSE) +
  geom_point(show.legend = FALSE) +
  #geom_hline(yintercept = K) +
  facet_wrap(vars(size_category), scales = "free") +
  theme_bw() 
  
  # scale_x_continuous(breaks = unique(erad_quarter_results$all_quarters$Quarter), labels = unique(erad_quarter_results$all_quarters$Quarter))

```

```{r jags_model}

# JAGS Removal Estimation Model - version 2
sink("removal_model.jags")
cat("
model {

# Set up first row of N
for(k in 1:S) {
  p.miss[1,k,1:N_prior] <- rep(1/N_prior,N_prior)
  miss[1,k] ~ dcat(p.miss[1,k,1:N_prior])
  N[k,1,1] <-  N.base[k,1,1] + miss[1,k]
}

# Parameter priors

for(k in 1:S) {
  beta.p[k, 1] ~ dunif(0, 10)
  beta.p[k, 2] ~ dunif(0, 10)
  alpha.p[k, 1] ~ dunif(-20, 10)
  alpha.p[k, 2] ~ dunif(-20,10)
  for(v in vis_days) {
  beta.p[k, v] <- beta.p[k,1] 
  alpha.p[k, v] <- alpha.p[k,1]
  }
  for(r in trap_days) {
  beta.p[k, r] <- beta.p[k,2]
  alpha.p[k, r] <- alpha.p[k,2]
  }
}

## Survival hyperparameter - one set for when ADS has occurred, one for when it hasn't
# 
# for(m in 1:2) {
#   s1.day[m] ~ dbeta(1,1)
#   s2.day[m] ~ dbeta(1,1)
#   s3.day[m] ~ dbeta(1,1)
#   s4.day[m] ~ dbeta(1,1)
# }
s1.day ~ dbeta(1,1)
s2.day ~ dbeta(1,1)
s3.day ~ dbeta(1,1)
s4.day ~ dbeta(1,1)


# Size transition hyperparameter
t1.day ~ dbeta(1,1) # small -> medium
t2.day ~ dbeta(1,1) # medium -> large
t3.day ~ dbeta(1,1) # large -> xlarge

# # Fecundity hyperparameter
# f2.day ~ dgamma(1,0.3) # medium
# f3.day ~ dgamma(1,0.3) # for both large and xlarge
# Intercepts (a) and slopes (b)
a1 ~ dunif(0, 10)
a2 ~ dunif(0, 10)
b1 ~ dunif(0, 5)
b2 ~ dunif(0, 5)


# Setting up parameters to be sensitive to days between primary sampling periods
for(t in 1:(Q-1)) {
  # Survival
  # s1[t] <- pow(s1.day[ADS_quarter_counter[t]], days_btwn[t])
  # s2[t] <- pow(s2.day[ADS_quarter_counter[t]], days_btwn[t])
  # s3[t] <- pow(s3.day[ADS_quarter_counter[t]], days_btwn[t])
  # s4[t] <- pow(s4.day[ADS_quarter_counter[t]], days_btwn[t])
  s1[t] <- pow(s1.day, days_btwn[t])
  s2[t] <- pow(s2.day, days_btwn[t])
  s3[t] <- pow(s3.day, days_btwn[t])
  s4[t] <- pow(s4.day, days_btwn[t])
  # Size transition
  t1[t] <- 1 - pow((1 - t1.day), days_btwn[t])
  t2[t] <- 1 - pow((1 - t2.day), days_btwn[t])
  t3[t] <- 1 - pow((1 - t3.day), days_btwn[t])
  # Fecundity
  f2[t] <- a1 + b1*(days_btwn[t]/91)
  f3[t] <- a2 + b2*(days_btwn[t]/91)
  f4[t] <- f3[t]
}

# Transition matrix (used for population size class growth & reproduction between primary sampling periods)
for(t in 1:(Q-1)){
  P[1,1,t] <- s1[t]*(1-t1[t])
  P[1,2,t] <- f2[t]
  P[1,3,t] <- f3[t]
  P[1,4,t] <- f4[t]
  P[2,1,t] <- t1[t]*s1[t]
  P[2,2,t] <- s2[t]*(1-t2[t])
  P[2,3,t] <- 0
  P[2,4,t] <- 0
  P[3,1,t] <- 0
  P[3,2,t] <- t2[t]*s2[t]
  P[3,3,t] <- s3[t]*(1-t3[t])
  P[3,4,t] <- 0
  P[4,1,t] <- 0
  P[4,2,t] <- 0
  P[4,3,t] <- t3[t]*s3[t]
  P[4,4,t] <- s4[t]
}


for(t in 1:Q) { # start primary sampling period loop  
  for(k in 1:S) { # start size class loop
      for(i in 1:I) { # start secondary sampling instances loop
      # Calculate encounter probability for each method, secondary sampling instance and primary sampling period
      # Odd columns are visual, even columns are trap
        logit(p[k,i,t]) <- alpha.p[k,i] + beta.p[k,i] * log(xi[i,t])
      #***** version below runs, but is not method specific *****
      #  logit(p[k,i,t]) <- alpha.p[k] + beta.p[k] * log(xi[i,t]) # effort is not size-dependent
      # Calculate removals based on encounter probability and M (population in within i instance)
        Y[k,i,t] ~ dbin(p[k,i,t],N[k,i,t])
      # Calculate N using last time step N minus summed removals
        N[k,i+1,t] <- N[k,i,t] - Y[k,i,t]
      } # end secondary sampling instances loop
  # Calculate remaining population at the end of the primary sampling period
    R[k,t] <- N[k,I,t] - Y[k,I,t]
  } # end size class loop
} # end primary sampling period loop

for (t in 1:(Q-1)) { # start operations between primary sampling period loop
  # Calculate population at beginning of primary sampling period using remaining population from the end of previous sampling period X transition matrix
    D[1,t] ~ dpois(R[1,t]*P[1,1,t] + R[2,t]*P[1,2,t] + R[3,t]*P[1,3,t] + R[4,t]*P[1,4,t])
    D[2,t] ~ dpois(R[1,t]*P[2,1,t] + R[2,t]*P[2,2,t])
    D[3,t] ~ dpois(R[2,t]*P[3,2,t] + R[3,t]*P[3,3,t])
    D[4,t] ~ dpois(R[3,t]*P[4,3,t] + R[4,t]*P[4,4,t])
    # Set up first sampling instance of next primary sampling period
    for(k in 1:S){ # start size class loop
      N[k,1,t+1] <- D[k,t]
    } # end size class loop
} # end between primary sampling period loop

for(t in 1:Q) { #start primary sampling period loop
  # Summing all size classes into a single N for each primary sampling period
  N.sum[t] <- sum(N[,1,t])
} # end primary sampling period loop

} # end model
", fill= TRUE)
sink()
```

```{r alternative_1_estimation}

# Reading in IBM results, if needed
erad_results_list <- readRDS(file = here("Results", "scenario_1", "IBM_outputs_25.RDS"))

# Quarters with observations
obs_methods <- erad_methods[c(2:3)]
# Values needed for array dimensions & loops
S <- length(size_class_names) # number of size classes
Q <- length(unique(unlist(erad_quarters[obs_methods]))) # Primary sampling periods (quarters)
I <- rep(max(length(erad_days[[obs_methods[1]]]), length(erad_days[[obs_methods[2]]]))*2, Q) # Secondary sampling periods (days within each quarter) - redo this later, once I re-do how erad_days is formatted to allow it to vary between quarters

# Days between primary sampling periods when method is used
# For visual data
date_diff <- vector()
for(t in 1:(Q-1)) {
  date_diff[t] <- ((erad_quarters[[2]][t+1]-1)*91 + erad_days[[2]][1]) - 
    ((erad_quarters[[2]][t]-1)*91 + max(unlist(erad_days[2])))
}

# Creating vectors for trap and vis days 
vis_days <- seq(3, I[1], 2) # odd days are visual 
trap_days <- seq(4, I[1], 2) # even days are trap

# Initial N prior (based on area size)
N_prior <- 50*area_size

# Parameters monitored
parameters <- c("N", "N.sum", "p")

# MCMC settings
ni <- 20000
nt <- 1
nb <- 10000
nc <- 3

# List to capture jags output (not saving parameters because of space)
jags_output_list <- list()

for(variant in 11:15) {
  # Reformat simulation results
  erad_reformatted_v2 <- all_observations_fun(erad_results_ts = erad_results_list[[variant]],
                                              methods = obs_methods)
  # Isolate observations and effort per day
  removals_array_v2 <- array(dim = c(S, I[1], Q))
  effort_array_v2 <- array(dim = c(I[1], Q))
  for(q in 1:Q) {
    for(i in 1:(I[q]/2)) {
      removals_array_v2[, (i*2 - 1):(i*2), q] <- cbind(erad_reformatted_v2$observation[1,,i,q], erad_reformatted_v2$observation[2,,i,q])
      effort_array_v2[(i*2 - 1):(i*2), q] <- cbind(erad_reformatted_v2$effort[1,i,q], erad_reformatted_v2$effort[2, i, q])
    }
  }
  ##################### Creating all inputs for jags model ###########
  # Initial values for N (i.e. N[k, 1, 1])
  Y <- removals_array_v2
  N.base <- array(NA_real_, dim = c(S, I[1], Q))
  for(k in 1:S) {
    N.base[k,1,1] <- sum(Y[k,,1:Q])
  }
  
  # initialize D to > than the number that will be removed in the following year
  Y.remove1 <- vector()
  Y.remove2 <- vector()
  Y.remove3 <- vector()
  Y.remove4 <- vector()
  for(t in 1:Q){
    Y.remove1[t] <- sum(Y[1,,t])
    Y.remove2[t] <- sum(Y[2,,t])
    Y.remove3[t] <- sum(Y[3,,t])
    Y.remove4[t] <- sum(Y[4,,t])
  }
  
  D.init <- array(NA,dim = c(S,(Q-1)))
  for(t in 1:(Q-1)){
    D.init[1,t] <- Y.remove1[t+1] + 1
    D.init[2,t] <- Y.remove2[t+1] + 1
    D.init[3,t] <- Y.remove3[t+1] + 1
    D.init[4,t] <- Y.remove4[t+1] + 1
  }
  
  # Initial values for select parameters
  inits <- function (){
    list(D = D.init)
    # beta.p = runif(4,0,10),
    # alpha.p = runif(4,-10,10))
    
  }
  # Bundle data together
  data <- list(Y = removals_array_v2,
               S = S, I = I[1], Q = Q, 
               xi = effort_array_v2, 
               days_btwn = date_diff, 
               N.base = N.base,
               vis_days = vis_days,
               trap_days = trap_days,
               N_prior = N_prior)
  # ADS_quarters = ADS_quarters,
  # ADS_quarter_counter = ADS_quarter_counter)
  
  # Call JAGS Function
  jags_output_list[[variant]] <- jags(data, 
                                inits, 
                                parameters, 
                                "removal_model.jags", 
                                n.chains = nc, 
                                n.thin = nt, 
                                n.iter = ni,
                                n.burnin = nb)
  
  print(paste0("iteration ", variant))
}

saveRDS(jags_output_list, file = here("Results" , "scenario_1", "jags_output_list_11-15.rds"))
# Constructing results lists - memory limit issues, so had to do this piecemeal
jags_1 <- readRDS(file = here("Results" , "scenario_1", "jags_output_list_1-5.rds"))
jags_2 <- readRDS(file = here("Results" , "scenario_1", "jags_output_list_6-10.rds"))
jags_2 <- jags_2[c(6:10)]
jags_outputs_10_list <- c(jags_1, jags_2) 
remove(jags_1)
remove(jags_2)
jags_3 <- readRDS(file = here("Results" , "scenario_1", "jags_output_list_11-15.rds"))
jags_3 <- jags_3[c(11:15)]
jags_outputs_15_list <- c(jags_outputs_10_list, jags_3) 
remove(jags_3)
remove(jags_outputs_10_list)

est_v_sim_N_plot_list <- list()
for(variant in 1:15) {
  # Mean N estimates vs simulated real N
est_v_sim_N_plot_list[[variant]] <- estimated_N_plots(jags_output = jags_outputs_15_list[[variant]],
                       erad_quarter_results = erad_results_list[[variant]],
                       erad_quarters = erad_quarters)
}

```

```{r estimation_test}
erad_reformatted_v2 <- all_observations_fun(erad_results_ts = erad_results_list[[1]],
                                              methods = obs_methods)

# Isolate observations and effort per day
  removals_array_v2 <- array(dim = c(S, I[1], Q))
  effort_array_v2 <- array(dim = c(I[1], Q))
  for(q in 1:Q) {
    for(i in 1:(I[q]/2)) {
      removals_array_v2[, (i*2 - 1):(i*2), q] <- cbind(erad_reformatted_v2$observation[1,,i,q], erad_reformatted_v2$observation[2,,i,q])
      effort_array_v2[(i*2 - 1):(i*2), q] <- cbind(erad_reformatted_v2$effort[1,i,q], erad_reformatted_v2$effort[2, i, q])
    }
  }
  ##################### Creating all inputs for jags model ###########
# Initial values for N (i.e. N[k, 1, 1])
Y <- removals_array_v2
N.base <- array(NA_real_, dim = c(S, I[1], Q))
for(k in 1:S) {
  N.base[k,1,1] <- sum(Y[k,,1:Q])
}

# initialize D to > than the number that will be removed in the following year
Y.remove1 <- vector()
Y.remove2 <- vector()
Y.remove3 <- vector()
Y.remove4 <- vector()
for(t in 1:Q){
  Y.remove1[t] <- sum(Y[1,,t])
  Y.remove2[t] <- sum(Y[2,,t])
  Y.remove3[t] <- sum(Y[3,,t])
  Y.remove4[t] <- sum(Y[4,,t])
}

D.init <- array(NA,dim = c(S,(Q-1)))
for(t in 1:(Q-1)){
  D.init[1,t] <- Y.remove1[t+1] + 1
  D.init[2,t] <- Y.remove2[t+1] + 1
  D.init[3,t] <- Y.remove3[t+1] + 1
  D.init[4,t] <- Y.remove4[t+1] + 1
}

# Initial values for select parameters
inits <- function (){
  list(D = D.init)
       # beta.p = runif(4,0,10),
       # alpha.p = runif(4,-10,10))
  
}
  # Bundle data together
data <- list(Y = removals_array_v2,
             S = S, I = I[1], Q = Q, 
             xi = effort_array_v2, 
             days_btwn = date_diff, 
             N.base = N.base,
             vis_days = vis_days,
             trap_days = trap_days,
             N_prior = N_prior)
             # ADS_quarters = ADS_quarters,
             # ADS_quarter_counter = ADS_quarter_counter)

# Parameters monitored
parameters <- c("N", "N.sum", "alpha.p", "beta.p", "s1", "s2", "s3", "s4", 
                "f2", "f3", "f4", "t1", "t2", "t3", "p",  "R", "D", "s1.day", "s2.day", "s3.day", "s4.day", "t1.day", "t2.day", "t3.day",
                "a1", "a2", "b1", "b2")


# Call JAGS Function
output_jags <- jags(data, 
                    inits, 
                    parameters, 
                    "removal_model.jags", 
                    n.chains = nc, 
                    n.thin = nt, 
                    n.iter = ni,
                    n.burnin = nb)

# Mean N estimates vs simulated real N
est_v_sim_N_plots <- estimated_N_plots(jags_output = output_jags,
                       erad_quarter_results = erad_quarter_results,
                       erad_quarters = erad_quarters)

# Calculating true vital rates 
true_vital_rates <- true_vital_rates_v1_fun(all_erad_quarters = erad_quarters[c("visual","trap")],
                          erad_results_df = erad_results_list[[1]])

# Traceplots of parameters
traceplot(output_jags, parameters = c("s1","s2","s3","s4"))
traceplot(output_jags, parameters = c("s1.day", "s2.day", "s3.day", "s4.day"))
traceplot(output_jags, parameters = c("t1","t2","t3"))
traceplot(output_jags, parameters = c("t1.day", "t2.day", "t3.day"))
traceplot(output_jags, parameters = c("f2","f3","f4"))
#traceplot(output_jags, parameters = c("f2.day", "f3.day"))
traceplot(output_jags, parameters = c("a1", "a2"))
traceplot(output_jags, parameters = c("b1", "b2"))
traceplot(output_jags, parameters = c("p"))
traceplot(output_jags, parameters = c("alpha.p"))
traceplot(output_jags, parameters = c("beta.p"))

```

### Estimation model result metrics

What outputs do I need, and how will I combine results from many runs without having to save the actual jags outputs (which will be difficult or impossible because of memory limitations).

```{r estimation_model_metrics}

# Calculating the number as well as proportion of total population in each size class at the end of the timeseries
N_k <- list()
prop_N_k <- list()
for(variant in 1:15) {
  N_k[[variant]] <- vector()
  for(k in 1:S) {
    N_k[[variant]][k] <- jags_outputs_15_list[[variant]]$mean$N[k,I[Q],Q]
  }
  prop_N_k[[variant]] <- N_k[[variant]]/jags_outputs_15_list[[variant]]$mean$N.sum[Q]
}


# Calculating how many runs reach a threshold of <1% of total N for any of the upper 3 size classes
prop_under_0.1 <- c("medium" = 0, "large" = 0, "xlarge" = 0)
for(variant in 1:15) {
  for(k in 2:S) {
  if(prop_N_k[[variant]][k] < 0.01) {
    prop_under_0.1[k-1] <- prop_under_0.1[k-1] + 1
  } else {
    prop_under_0.1[k-1] <- prop_under_0.1[k-1]
  }
  }
}
# proportion out of the total runs done:
prop_under_0.1 <- prop_under_0.1/length(jags_outputs_15_list)
# 7% of runs (1) had medium snakes get under 1%, 27% (4) had large snakes get under 1%, and 40% (6) had xlarge snakes go under 1%

# Calculating how many runs reach a threshold of <10 snakes in any of the upper 3 size classes
prop_under_10 <- c("medium" = 0, "large" = 0, "xlarge" = 0)
for(variant in 1:length(jags_outputs_15_list)) {
  for(k in 2:S) {
  if(N_k[[variant]][k] < 10) {
    prop_under_10[k-1] <- prop_under_10[k-1] + 1
  } else {
    prop_under_10[k-1] <- prop_under_10[k-1]
  }
  }
}
prop_under_10 <-prop_under_10/length(jags_outputs_15_list)
# 13% (2) under 10 medium snakes, 27% (4) under 10 large snakes, 53% (8) under 10 xlarge snakes

## Now, looking for runs that meet the criteria that ALL of the upper 3 size classes
# Number under 10
all_under_10 <- 0
for(variant in 1:length(jags_outputs_15_list)) {
 if(N_k[[variant]][2] < 10 & N_k[[variant]][3] < 10 & N_k[[variant]][4] < 10) {
   all_under_10 <- all_under_10 + 1
 } else {
   all_under_10 <- all_under_10
 }
}

# 0 runs meet the criteria that all 3 size classes are under 10 individuals (there is one the has all 3 under 30 though)

# Proportion under 1%
all_under_0.01 <- 0
for(variant in 1:length(jags_outputs_15_list)) {
 if(prop_N_k[[variant]][2] < 0.01 & prop_N_k[[variant]][3] < 0.01 & prop_N_k[[variant]][4] < 0.01) {
   all_under_0.1 <- all_under_0.1 + 1
 } else {
   all_under_0.1 <- all_under_0.1
 }
}

# 0 runs meet the criteria that all 3 size classes are under 1% - could look at allowing a higher percent for medium snakes since they aren't as susceptible to most methods



```

#### Alternative 2 - management rule (ADS then visual survey only)

In the second eradication scenario alternative, ADS will occur across the entire area, with visual survey occurring at regular intervals to enable population monitoring to occur. When the population is estimated to be at a certain threshold (\<1% of population in medium, large and x-large size classes), it will switch to visual survey only

There will be 2 ADS rounds of 3 drops (spaced a week apart) in each quarter, with 3 weeks between them. Visual surveys will occur at the end of the quarter, and the first quarter will only have visual survey (to establish a beginning estimate of the population). Visual surveys will occur every night for 2 weeks, and can be done in a number of ways, these are my top two options:

-   8 transects per night for 14 nights would cover the whole 113 transects (112, but close enough for now) once in the 2 week period - this requires 2 teams (of 2 people)

-   16 transects per night would allow the whole area to be covered twice in the time period (requires 4 teams)

```{r alternative_2_set_up}

# Number of teams for visual survey
teams <- 2

# Adjusting effort hours per method if necessary (there are defaults)
effort_erad_methods <- list()
effort_erad_methods$ADS <- 4
effort_erad_methods$visual <- 4*2*teams


# Parameters that may be changed or subject to sensitivity analysis or to simulate over
# Set study/eradication area size, which dictates both K and the initial population
area_size <- 50 # increase to 50 for real runs, this is just to get everything working quicker

# Set carrying capacity for this population:
K <- 119*area_size

## For initial population, based on previous runs to find roughly eqiulibrium N and size distribution:
N <- 100*area_size
size_dist <- c(0.6, 0.1, 0.1, 0.2)


# Growth probability (p_g)
g_density_prob <- 0.75 

# Number of quarters to generate - 1 year
erad_quarter_time_step <- 4
day_time_step <- 91

# Quarters where eradication methods are used, and which days in that quarter:
erad_quarters <- list()
erad_quarters$ADS <- c(2:4)
erad_quarters$visual <- c(1:4)
erad_days <- list()
erad_days$ADS <- c(seq(7*2, 7*4, 7), seq(7*7, 7*9, 7))
erad_days$visual <- c((7*11):(7*13-1))


# Coverage for each method (totally arbitrary, adjust later)
erad_coverage <- list()
erad_coverage$ADS <- 1
erad_coverage$visual <- 8/113

# Overlap of ADS over transects
ADS_overlap_on_transect <- 1 # i.e. total area coverage, by at least one method 

# Running model 
erad_quarter_results <- quarter_operations(initial_N = N, 
                                           initial_size_dist = size_dist, 
                                           p_g = g_density_prob,
                                           lambda = lambda,
                                           total_quarters = erad_quarter_time_step,
                                           total_days = day_time_step,
                                           erad = "on",
                                           erad_method = erad_methods)

# Plotting the total population in each quarter
erad_plot_1 <- ggplot(erad_quarter_results$all_quarters, 
                      aes(x = Quarter, fill = size_category)) +
  geom_bar() +
  geom_hline(yintercept = K) +
  theme_bw() +
  scale_x_continuous(breaks = unique(erad_quarter_results$all_quarters$Quarter), labels = unique(erad_quarter_results$all_quarters$Quarter))


```

```{r alternative_2_variants}

# Incorporating uncertainty about the starting population by simulating a range of values - starting with 25 to see how long it takes to run
N_list <- round(rnorm(25, 100, 10))*area_size

# List of quarter results
erad_results_list <- list()

for(variant in 1:length(N_list)) {
  # Running model 
  erad_results_list[[variant]] <- quarter_operations(initial_N = N_list[variant], 
                                           initial_size_dist = size_dist, 
                                           p_g = g_density_prob,
                                           lambda = lambda,
                                           total_quarters = erad_quarter_time_step,
                                           total_days = day_time_step,
                                           erad = "on",
                                           erad_method = erad_methods[c(1:2)])
  print(paste0("iteration ", variant, " is complete"))
}

# Save outputs 
saveRDS(erad_results_list, file = here("Results", "scenario_1", "IBM_outputs_alt_2_25.RDS"))


erad_plot_data <- list()
for(variant in 1:length(erad_results_list)) {
  erad_plot_data[[variant]] <- list()
  results <- erad_results_list[[variant]]$all_quarters
  for(quarter in 1:erad_quarter_time_step) {
    erad_plot_data[[variant]][[quarter]] <- as.data.frame(matrix(NA, nrow = 4, ncol = 2))
    colnames(erad_plot_data[[variant]][[quarter]]) <- c("size_category", "N")
    for(size in 1:length(size_class_names)) {
      erad_plot_data[[variant]][[quarter]][size, 1] <- size_class_names[size]
      erad_plot_data[[variant]][[quarter]][size, 2] <- nrow(results[results$Quarter == (quarter+1) & results$size_category == size_class_names[size],])
    }
  }
  names(erad_plot_data[[variant]]) <- paste0("Quarter_", c(1:4))
}
names(erad_plot_data) <- paste0("variant_", c(1:25))  

erad_plot_data_melted <- melt(erad_plot_data, id.vars = colnames(erad_plot_data[[1]][[1]]))
colnames(erad_plot_data_melted)[c(3:4)] <- c("Quarter", "variant")
erad_plot_data_melted$size_category <- factor(erad_plot_data_melted$size_category, levels = size_class_names)
erad_plot_data_melted$variant <- factor(erad_plot_data_melted$variant, levels = paste0("variant_", c(1:25)))

variants_plot <- ggplot(erad_plot_data_melted, aes(x = Quarter, y = N, color = variant)) +
  geom_path(aes(group = variant)) +
  geom_point() +
  #geom_hline(yintercept = K) +
  facet_wrap(vars(size_category), scales = "free") +
  theme_bw() 
  # scale_x_continuous(breaks = unique(erad_quarter_results$all_quarters$Quarter), labels = unique(erad_quarter_results$all_quarters$Quarter))


```

```{r model_metrics_fun}



## Function to calculate the number as well as proportion of total population in each size class at the end of the timeseries
model_metric_1_fun <- function(input_list,
                               type_of_input = c("simulated", "estimated"),
                               threshold = c(prop = 0.01, N = 10)) {
  # Number of iterations for loops
  iterations <- length(input_list)
  # Isolating N values based on what type of input 
  last_Ns <- list()
  if(type_of_input == "estimated") {
    for(variant in 1:iterations) {
      last_Ns[[variant]] <- vector()
      for(k in 1:S) {
        last_Ns[[variant]][k] <- input_list[[variant]]$mean$N[k,I[Q],Q]
      }
    }
  } else if(type_of_input == "simulated") {
    for(variant in 1:iterations) {
      last_Ns[[variant]] <- list()
      results <- erad_results_list[[variant]]$quarter_timeseries[[erad_quarter_time_step+1]]
      for(snake in 1:nrow(results)) {
        results$size_class[snake] <- size_class_fun(results$SVL[snake])
      }
      for(k in 1:length(size_class_names)) {
        last_Ns[[variant]][k] <- nrow(results[results$size_class == size_class_names[k],])
      }
      last_Ns[[variant]] <- unlist(last_Ns[[variant]])
    }
  }
  
  N_k <- list()
  prop_N_k <- list()
  for(variant in 1:iterations) {
    N_k[[variant]] <- vector()
    for(k in 1:length(size_class_names)) {
      N_k[[variant]][k] <- last_Ns[[variant]][k]
    }
    prop_N_k[[variant]] <- N_k[[variant]]/sum(last_Ns[[variant]])
  }
  # Calculate the number of runs that meets the threshold, based on the type of threshold
    prop_under <- c("medium" = 0, "large" = 0, "xlarge" = 0)
    N_under <- c("medium" = 0, "large" = 0, "xlarge" = 0)
    for(variant in 1:iterations) {
      for(k in 2:length(size_class_names)) {
          if(prop_N_k[[variant]][k] < threshold[1]) {
            prop_under[k-1] <- prop_under[k-1] + 1
          } else {
            prop_under[k-1] <- prop_under[k-1]
          }
          if(N_k[[variant]][k] < threshold[2]) {
            N_under[k-1] <- N_under[k-1] + 1
          } else {
            N_under[k-1] <- N_under[k-1]
          }
      }
    }

  # Proportion of runs under the threshold:
  prop_under <- prop_under/iterations
  N_under <- N_under/iterations
  
  # Whether all upper size classes meet the same threshold
  all_prop_under <- 0
  all_N_under <- 0
  for(variant in 1:iterations) {
    if(prop_N_k[[variant]][2] < threshold[1] &
       prop_N_k[[variant]][3] < threshold[1] &
       prop_N_k[[variant]][4] < threshold[1]) {
      all_prop_under <- all_prop_under + 1
    } else {
      all_prop_under <- all_prop_under
    }
    
    if(N_k[[variant]][2] < threshold[2] & 
       N_k[[variant]][3] < threshold[2] & 
       N_k[[variant]][4] < threshold[2]) {
      all_N_under <- all_N_under + 1
    } else {
      all_N_under <- all_N_under
    }
  }
  all_prop_under <- all_prop_under/iterations
  all_N_under <- all_N_under/iterations
  
  return(list(last_N_k = N_k,
              last_prop_k = prop_N_k,
              any_prop_under_threshold = list("prop" = prop_under,
                                           "N" = N_under),
              all_under_threshold = c("prop" = all_prop_under,
                                      "N" = all_N_under)))
}


x <- model_metric_1_fun(erad_results_list, "simulated")
                        



```
